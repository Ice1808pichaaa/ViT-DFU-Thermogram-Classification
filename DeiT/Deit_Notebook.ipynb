{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NOc2Kxys-k1"
   },
   "source": [
    "# **Setup & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5sicZCZ30DM",
    "outputId": "dcfc7b96-88c8-473d-b8f7-5da3850ba6f3"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnZqGrLthLiP",
    "outputId": "58c6c2b0-10c4-4c15-af27-5d2b83def842"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"transformers>=4.44\"\n",
    "!pip install -U \"accelerate>=0.33\"\n",
    "!pip install -U \"datasets>=2.20\"\n",
    "!pip install -U \"evaluate>=0.4\"\n",
    "!pip install \"huggingface-hub>=0.34.0,<1.0\"\n",
    "!pip install -U scikit-learn\n",
    "!pip install -U sacrebleu\n",
    "!pip install -U gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSK4NFtfHMfm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "from transformers import (\n",
    "    DeiTForImageClassification,\n",
    "    DeiTImageProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    "    pipeline,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08IgchiktFty"
   },
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AESL0T_SOzJH",
    "outputId": "25068e9a-a32b-44ae-953c-ba1fa55c3612"
   },
   "outputs": [],
   "source": [
    "!gdown 1fr-ZuEeJGi5kE1pA3EzlTvHfr-oN5U0P\n",
    "!unzip Dataset_DFUs.zip\n",
    "!rm Dataset_DFUs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MT410tuqOzJH",
    "outputId": "89e839ec-5931-4a88-a982-80c7d3c66f83"
   },
   "outputs": [],
   "source": [
    "count = glob.glob('Dataset/**/*.png', recursive=True)\n",
    "print(\"Dataset amount:\", len(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihDMWjr4HMfp",
    "outputId": "73004dda-7593-41c5-ebd7-b1a6cdb0578f"
   },
   "outputs": [],
   "source": [
    "img_name = []\n",
    "img_label = []\n",
    "\n",
    "for file in glob.glob('Dataset/**/*.png', recursive=True):\n",
    "    img_name.append(file)\n",
    "    img_label.append(int(file.split(\"/\")[-2]))\n",
    "\n",
    "df_master = pd.DataFrame({\n",
    "    'img_path': img_name,\n",
    "    'label': img_label\n",
    "})\n",
    "\n",
    "print(\"Total images loaded:\")\n",
    "print(df_master['label'].value_counts())\n",
    "\n",
    "X = df_master['img_path']\n",
    "y = df_master['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2bnNj7n6urNa",
    "outputId": "17410847-49fc-40d0-dceb-0a8a2a6d332d"
   },
   "outputs": [],
   "source": [
    "df_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRBw-L0EtWfp"
   },
   "source": [
    "# **Configuration & Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0,
     "referenced_widgets": [
      "c06e822dd42e410c836db6e8911f407d",
      "f84c771492b64ea1a185735037ab0129",
      "49f43f44f32244d7a07adb5738544c8b",
      "4b6297c1542441d48e88ded6bd2d4386",
      "5e2067decbb640899a384af0392c3b9d",
      "14419a3b7ad3480eb151f505062fb34f",
      "d6ed890f663043528577934d55f066bc",
      "fa77d7ef3de247c5bbff612801f4dae9",
      "2e672812fb4a46bea7d341205a8b5560",
      "ebce1ac7e17f4b1fae50c2e38b654e5b",
      "a1e9f8bf77cb4885b239a8eb7155bfe1",
      "fa8e231a849c44f2aae2440c09a54a36",
      "f32186b4736549c8900015cf5612f245",
      "2e1363f5766445a3a1e1105c710f9154",
      "88ff157ede144ec581d224ba7c59e4e4",
      "78887c8787c84861b98e7aef2e0ebc04",
      "7dffcbe437c247e3b0312f27f8cd8a36",
      "8ebd198a405a43a6b90c73e11fd48096",
      "7b019b61ecae4996907a4024a179e75d",
      "831805e208874f18ab60fdbea9b539b5",
      "2ed402711e8247b597bd7a02586a0b63",
      "b84da478e4af4017a32216edff12fce3",
      "b95dbdecef4e4876abd4c08a71281da1",
      "81967ea3bd7245f6abcca4f5ada7bce6",
      "6995e72c796f4d9b965354be4812f585",
      "10c7db61561f4e099aab505f420bc5b8",
      "505854bb22bf46a7bd4d560eee55865e",
      "3a42f377eb42477ebddb9dadd2f27a83",
      "1dc96af77ece40b1b0dfda69e1dad724",
      "9850eb8fc633474eae3c48c087c17675",
      "30b19d13fbcb454e91220d3df205a1fd",
      "1690602f8d5a449ebca7c83ab72d8ef2",
      "144afe995d724a28a7197320bdac2ba8",
      "9c01a975c04b434badb807da28806c7e",
      "7c92b5bd2a33488da4642be8569361d7",
      "0774599f013e48a2a801d1a8d687f547",
      "5394f8b8aa1e40fea736314c81665832",
      "2be4f975a7d340cdabb94c9472358f68",
      "ee7edc2d3e22436fa61126ca76da297d",
      "16553caf819c4c36ba544abdfe70b719",
      "89236d30c80c42d192202116add1ae06",
      "e2a1e0e3aa7f41458c225def2c70a87c",
      "d9d6d4591c3448cfb104381bdf49d737",
      "877ecb1560ec49c4abe366d1c8b09054",
      "3a2747a347444fd997b9d2c40ec9d1b7",
      "edb36666ce7b411088f02baf21dea778",
      "c1933159c3da4f74a78120deb0aa6093",
      "06ab8a464e274af28b19b730f7cd1c39",
      "541b923ec8aa42bcb27d53130518db90",
      "f5f383b4eb79445d998535e75f7c0518",
      "16a5f9d53a50403888c17aca46021f1a",
      "aa00534357984212a44eea6563c0e4a3",
      "72410d7295d04178acadd1d11eab87a1",
      "c1ae6ee20fb643cf933321101db3e424",
      "5ae64fa698614ae2a2ddd2c6b4a8b54d"
     ]
    },
    "id": "Xfh12JISD95W",
    "outputId": "6bee0a1f-b063-42e2-9284-5affe250ff44"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'facebook/deit-base-distilled-patch16-224'\n",
    "feature_extractor = DeiTImageProcessor.from_pretrained(model_checkpoint)\n",
    "\n",
    "id2label = { 0: '0', 1: '1' }\n",
    "label2id = { '0': 0, '1': 1 }\n",
    "\n",
    "def transform(example_batch):\n",
    "    inputs = feature_extractor([Image.open(x) for x in example_batch['img_path']], return_tensors='pt')\n",
    "    inputs['labels'] = example_batch['label']\n",
    "    return inputs\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "acc_metric  = evaluate.load(\"accuracy\")\n",
    "prec_metric = evaluate.load(\"precision\")\n",
    "rec_metric  = evaluate.load(\"recall\")\n",
    "f1_metric   = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\":  acc_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"precision\": prec_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
    "        \"recall\":    rec_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
    "        \"f1\":        f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOs1XD3tteF3"
   },
   "source": [
    "# **Cross-Validation Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZptheodoOzJI",
    "outputId": "46e95d15-e2ca-4ba5-9aba-befbd29cec7b"
   },
   "outputs": [],
   "source": [
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights_array, dtype=torch.float32)\n",
    "\n",
    "print(f\"Using class weights: {class_weights_tensor}\")\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = class_weights.to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        if self.class_weights is not None and labels is not None:\n",
    "            loss_fct = CrossEntropyLoss(weight=self.class_weights)\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        else:\n",
    "            loss = outputs.loss if outputs.loss is not None else super().compute_loss(model, inputs, return_outputs)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZSo-HX-S2xh"
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "all_metrics = []\n",
    "all_true_labels = np.array([], dtype=int)\n",
    "all_predictions = np.array([], dtype=int)\n",
    "fold_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tRR-p_74S4fS",
    "outputId": "5aa48cd4-682d-41b8-af2a-806ce8f7ad11"
   },
   "outputs": [],
   "source": [
    "print(\"--- Visualizing 5-Fold Split Distributions ---\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\n--- FOLD {fold + 1}/{N_SPLITS} ---\")\n",
    "\n",
    "    val_df = df_master.iloc[val_idx]\n",
    "    val_labels = y.iloc[val_idx]\n",
    "\n",
    "    val_counts = val_labels.value_counts().sort_index()\n",
    "    print(f\"Validation set distribution:\\n{val_counts}\\n\")\n",
    "\n",
    "    print(f\"Displaying 5 sample validation images for Fold {fold + 1}:\")\n",
    "\n",
    "    sample_df = val_df.sample(min(5, len(val_df)))\n",
    "    image_paths = sample_df['img_path'].tolist()\n",
    "    image_labels = sample_df['label'].tolist()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "    for i, (path, label) in enumerate(zip(image_paths, image_labels)):\n",
    "        try:\n",
    "            img = Image.open(path)\n",
    "            axs[i].imshow(img)\n",
    "            axs[i].set_title(f\"Label: {label}\")\n",
    "            axs[i].axis('off')\n",
    "        except FileNotFoundError:\n",
    "            axs[i].set_title(\"Image Not Found\")\n",
    "            axs[i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wdmni1ylxe4Z",
    "outputId": "3e793de4-e7ff-4043-d60c-2c739e7a26ad"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class_weights_tensor = class_weights_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iyi9WsjBtqsX"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0,
     "referenced_widgets": [
      "18dd6547c938463d8dc22873b5e2cd11",
      "aa893774506144678d87791b5162f6a8",
      "f4b9ead1680d4615941da5a1032f62aa",
      "c6b6b103acb045fd81be11f310351bd8",
      "67926e14bef54e27a609349695f05d5a",
      "bfdc94ef4e604abc9d83a6a07740550b",
      "7280539a8fb2415c910c5edbdb557eb9",
      "2704a59d8e464758a8cb4922d4812a76",
      "4d4deb1554374d31a7c71c7a63c8e584",
      "74c8fe486cd74fe6a266ce529d87b91c",
      "d43d1f85ced24f7ab1ca5a2ec33e8b55",
      "f9e068d181f14fda8de01340cf8ed324",
      "78992569bc574be99240171829b3f4b7",
      "88bc1bef25934aa9bf03be7571040421",
      "ceeb4551a10348a08ea7ea8fc3e79c11",
      "8a062959739e41fb8e8ccaa0a2691063",
      "3d6a9e7051e9401f9c35b290e7d76950",
      "b1988d742b4c4c2fbc2201959d12788a",
      "38e41dfd6bf14e8ab3df905f0cc7510f",
      "b5e30b54707d478b8486f0bb84d38b9d",
      "c1604057d8cd4585ba59fd3e6f0b0ace",
      "c1d22e7b1105485d9d684f10bbd1a1a0",
      "5a46b924df78460d8caf59db07906f8a",
      "0826df5443e247bfa7fa936d88746194",
      "da05eb009f7e450f9e39e92833bf18b4",
      "808c6f733b554e46a8dea5719b0721e8",
      "541706540b7d4037b3dd6783f2edd4cb",
      "7fea7553d85f49f19c60e48de4c2814e",
      "2923579c68b249daa1864f32e8830d7a",
      "0a5a67d353ed4da2a32d17eff4b4d09e",
      "6d5a13612d644b02899528130434e968",
      "a48227591e6342b79fea77f88b75892f",
      "1c57fcf080e445dabd81fe9816175a1e"
     ]
    },
    "id": "huYPmRM4OzJI",
    "outputId": "4f25cabe-caa7-4493-8a15-56956ce066c5"
   },
   "outputs": [],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\n--- FOLD {fold + 1}/{N_SPLITS} ---\")\n",
    "\n",
    "    set_seed(42 + fold)\n",
    "\n",
    "    train_df = df_master.iloc[train_idx]\n",
    "    val_df   = df_master.iloc[val_idx]\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df).with_transform(transform)\n",
    "    val_dataset   = Dataset.from_pandas(val_df).with_transform(transform)\n",
    "\n",
    "    model = DeiTForImageClassification.from_pretrained(\n",
    "        model_checkpoint,\n",
    "        num_labels=2,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"training_deit_fold_{fold+1}\",\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=16,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=15,\n",
    "        logging_steps=10,\n",
    "        learning_rate=3e-5,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.05,\n",
    "        save_total_limit=2,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        remove_unused_columns=False,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        load_best_model_at_end=True,\n",
    "        use_mps_device= torch.backends.mps.is_available(),\n",
    "        optim=\"adamw_torch\",\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=feature_extractor,\n",
    "        class_weights=class_weights_tensor,\n",
    "        # callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    best_dir = trainer.state.best_model_checkpoint or training_args.output_dir\n",
    "\n",
    "    export_dir = f\"export_deit_fold_{fold+1}\"\n",
    "\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    shutil.copytree(best_dir, export_dir, dirs_exist_ok=True)\n",
    "\n",
    "    feature_extractor.save_pretrained(export_dir)\n",
    "\n",
    "    torch.save({\"id2label\": id2label, \"label2id\": label2id}, os.path.join(export_dir, \"label_map.pt\"))\n",
    "\n",
    "    print(f\"[Fold {fold+1}] Saved best model to: {export_dir}\")\n",
    "\n",
    "    print(f\"[Fold {fold+1}] Best metric (F1):\", trainer.state.best_metric)\n",
    "    print(f\"[Fold {fold+1}] Best checkpoint:\", trainer.state.best_model_checkpoint)\n",
    "    print(f\"[Fold {fold+1}] Epochs actually trained:\", trainer.state.epoch)\n",
    "\n",
    "    fold_logs.append(trainer.state.log_history)\n",
    "\n",
    "    log_file_path = os.path.join(export_dir, f\"fold_{fold+1}_log_history.json\")\n",
    "    with open(log_file_path, 'w') as f:\n",
    "        json.dump(trainer.state.log_history, f, indent=4)\n",
    "    print(f\"[Fold {fold+1}] Saved log history to: {log_file_path}\")\n",
    "\n",
    "    print(f\"--- Evaluating Fold {fold+1} ---\")\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "\n",
    "    predictions_output = trainer.predict(val_dataset)\n",
    "    fold_preds = np.argmax(predictions_output.predictions, axis=1)\n",
    "\n",
    "    all_predictions = np.concatenate((all_predictions, fold_preds))\n",
    "    all_true_labels = np.concatenate((all_true_labels, predictions_output.label_ids))\n",
    "    all_probs_pos   = np.array([], dtype=float)\n",
    "\n",
    "    logits = predictions_output.predictions\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    probs = exp_logits / exp_logits.sum(axis=1, keepdims=True)\n",
    "    probs_pos = probs[:, 1]\n",
    "\n",
    "    all_probs_pos = np.concatenate((all_probs_pos, probs_pos))\n",
    "\n",
    "    del model, trainer, predictions_output\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "print(\"\\n--- Cross-Validation Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-XsdgX4tkZO"
   },
   "source": [
    "# **Results & Analysis for Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg_d61nLDhSn"
   },
   "source": [
    "## **Helper function to plot the graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83HovxKhz32p"
   },
   "outputs": [],
   "source": [
    "def curves_from_history(log_history):\n",
    "    df = pd.DataFrame(log_history)\n",
    "\n",
    "    if \"loss\" in df.columns:\n",
    "        train_curve = (\n",
    "            df[df[\"loss\"].notna()]\n",
    "            .groupby(\"epoch\", as_index=False)[\"loss\"]\n",
    "            .last()\n",
    "            .rename(columns={\"loss\": \"train_loss\"})\n",
    "        )\n",
    "    else:\n",
    "        train_curve = pd.DataFrame(columns=[\"epoch\", \"train_loss\"])\n",
    "\n",
    "    if \"eval_loss\" in df.columns:\n",
    "        agg_dict = {\n",
    "            \"eval_loss\": (\"eval_loss\", \"last\")\n",
    "        }\n",
    "        if \"eval_accuracy\" in df.columns:\n",
    "            agg_dict[\"eval_accuracy\"] = (\"eval_accuracy\", \"last\")\n",
    "        if \"eval_f1\" in df.columns:\n",
    "            agg_dict[\"eval_f1\"] = (\"eval_f1\", \"last\")\n",
    "\n",
    "        eval_curve = (\n",
    "            df[df[\"eval_loss\"].notna()]\n",
    "            .groupby(\"epoch\", as_index=False)\n",
    "            .agg(**agg_dict)\n",
    "        )\n",
    "    else:\n",
    "        eval_curve = pd.DataFrame(columns=[\"epoch\", \"eval_loss\", \"eval_accuracy\", \"eval_f1\"])\n",
    "\n",
    "    curve = pd.merge(train_curve, eval_curve, on=\"epoch\", how=\"outer\").sort_values(\"epoch\")\n",
    "    return curve\n",
    "\n",
    "def smooth_xy(x, y, points=200):\n",
    "    m = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x, y = np.asarray(x)[m], np.asarray(y)[m]\n",
    "\n",
    "    order = np.argsort(x)\n",
    "    x, y = x[order], y[order]\n",
    "\n",
    "    uniq_x, uniq_idx = np.unique(x, return_index=True)\n",
    "    uniq_y = y[uniq_idx]\n",
    "\n",
    "    if len(uniq_x) < 4:\n",
    "        x_dense = np.linspace(uniq_x.min(), uniq_x.max(), points)\n",
    "        y_dense = np.interp(x_dense, uniq_x, uniq_y)\n",
    "        return x_dense, y_dense\n",
    "\n",
    "    spline = make_interp_spline(uniq_x, uniq_y, k=3)\n",
    "\n",
    "    x_dense = np.linspace(uniq_x.min(), uniq_x.max(), points)\n",
    "    y_dense = spline(x_dense)\n",
    "\n",
    "    return x_dense, y_dense\n",
    "\n",
    "fold_curves = [curves_from_history(h) for h in fold_logs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxpgOMh6DuY9"
   },
   "source": [
    "## Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ma3i2Kkuz_Oy",
    "outputId": "84dd2351-d742-43ff-bf75-2cb94414d477"
   },
   "outputs": [],
   "source": [
    "for i, curve in enumerate(fold_curves, 1):\n",
    "    plt.figure()\n",
    "\n",
    "    x_acc, y_acc = smooth_xy(curve[\"epoch\"].values, curve[\"eval_accuracy\"].values)\n",
    "    plt.plot(x_acc, y_acc, label=\"Eval accuracy\", marker='')\n",
    "\n",
    "    x_f1, y_f1 = smooth_xy(curve[\"epoch\"].values, curve[\"eval_f1\"].values)\n",
    "    plt.plot(x_f1, y_f1, label=\"Eval F1\", marker='')\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Fold {i} — Accuracy & F1 per epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6Ude5PVe0DFL",
    "outputId": "f3c4b866-97cb-4b1e-a999-6b78ac186852"
   },
   "outputs": [],
   "source": [
    "for i, curve in enumerate(fold_curves, 1):\n",
    "    plt.figure()\n",
    "\n",
    "    x_tr, y_tr = smooth_xy(curve[\"epoch\"].values, curve[\"train_loss\"].values)\n",
    "    plt.plot(x_tr, y_tr, label=\"Train loss\", marker='')\n",
    "\n",
    "    x_ev, y_ev = smooth_xy(curve[\"epoch\"].values, curve[\"eval_loss\"].values)\n",
    "    plt.plot(x_ev, y_ev, label=\"Eval loss\", marker='')\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Fold {i} — Loss per epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "-nvxJAZ9BhRX",
    "outputId": "dd5be00c-b157-49ac-8cba-dc50594fc4d6"
   },
   "outputs": [],
   "source": [
    "all_eval = []\n",
    "all_train = []\n",
    "for c in fold_curves:\n",
    "    all_eval.append(c[[\"epoch\", \"eval_loss\", \"eval_accuracy\", \"eval_f1\"]].dropna())\n",
    "    all_train.append(c[[\"epoch\", \"train_loss\"]].dropna())\n",
    "\n",
    "avg_eval = (pd.concat(all_eval)\n",
    "            .groupby(\"epoch\", as_index=False)\n",
    "            .mean(numeric_only=True))\n",
    "avg_train = (pd.concat(all_train)\n",
    "             .groupby(\"epoch\", as_index=False)\n",
    "             .mean(numeric_only=True))\n",
    "\n",
    "plt.figure()\n",
    "x_train_loss, y_train_loss = smooth_xy(avg_train[\"epoch\"], avg_train[\"train_loss\"])\n",
    "plt.plot(x_train_loss, y_train_loss, label=\"Avg train loss\", marker='')\n",
    "x_eval_loss, y_eval_loss = smooth_xy(avg_eval[\"epoch\"],  avg_eval[\"eval_loss\"])\n",
    "plt.plot(x_eval_loss, y_eval_loss, label=\"Avg eval loss\", marker='')\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Average Loss across folds\")\n",
    "plt.legend(); plt.grid(True, alpha=0.3); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "x_eval_acc, y_eval_acc = smooth_xy(avg_eval[\"epoch\"], avg_eval[\"eval_accuracy\"])\n",
    "plt.plot(x_eval_acc, y_eval_acc, label=\"Avg eval accuracy\", marker='', color='orange')\n",
    "\n",
    "x_eval_f1, y_eval_f1 = smooth_xy(avg_eval[\"epoch\"], avg_eval[\"eval_f1\"])\n",
    "plt.plot(x_eval_f1, y_eval_f1, label=\"Avg eval F1\", marker='')\n",
    "\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Score\")\n",
    "plt.title(\"Average Eval Accuracy & F1 Score across folds\")\n",
    "plt.legend(); plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YadHyZLzxzS"
   },
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "bzn7uuDdfLf5",
    "outputId": "ed96b48c-117c-40e4-da55-be5d8bfd2816"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(all_true_labels, all_predictions)\n",
    "labels = [\"Class 0\", \"Class 1\"]\n",
    "\n",
    "plt.figure(figsize=(4.5, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"white\"\n",
    ")\n",
    "plt.title(\"Overall Confusion Matrix (all folds)\", pad=12)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s48gl1RUUB7"
   },
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "j83JbKj0dTma",
    "outputId": "aa50afed-2d34-4135-8d5a-fec97806ecf8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "\n",
    "all_metrics      = []\n",
    "all_true_labels  = []\n",
    "all_predictions  = []\n",
    "all_probs_pos    = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    fold_dir = f\"training_deit_fold_{fold}\"\n",
    "    ckpts = [os.path.join(fold_dir, c) for c in os.listdir(fold_dir) if c.startswith(\"checkpoint\")]\n",
    "    if not ckpts:\n",
    "        print(f\"No checkpoint found for fold {fold}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    ckpts.sort(key=lambda p: int(p.split(\"-\")[-1]))\n",
    "    latest_ckpt = ckpts[-1]\n",
    "    print(f\"--- Fold {fold}: loading {latest_ckpt} ---\")\n",
    "\n",
    "    val_df = df_master.iloc[val_idx].reset_index(drop=True)\n",
    "    val_dataset = Dataset.from_pandas(val_df).with_transform(transform)\n",
    "\n",
    "    model = DeiTForImageClassification.from_pretrained(latest_ckpt)\n",
    "\n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\"tmp_eval\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    eval_trainer = Trainer(\n",
    "        model=model,\n",
    "        args=eval_args,\n",
    "        data_collator=collate_fn,\n",
    "    )\n",
    "\n",
    "    preds_output = eval_trainer.predict(val_dataset)\n",
    "    logits = preds_output.predictions\n",
    "    y_true = preds_output.label_ids\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "\n",
    "    logits_shifted = logits - np.max(logits, axis=1, keepdims=True)\n",
    "    exp_logits = np.exp(logits_shifted)\n",
    "    probs = exp_logits / exp_logits.sum(axis=1, keepdims=True)\n",
    "    probs_pos = probs[:, 1]\n",
    "\n",
    "    all_true_labels.append(y_true)\n",
    "    all_predictions.append(y_pred)\n",
    "    all_probs_pos.append(probs_pos)\n",
    "\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, pos_label=1)\n",
    "    rec  = recall_score(y_true, y_pred, pos_label=1)\n",
    "    f1   = f1_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "    all_metrics.append({\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "    })\n",
    "\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "all_probs_pos   = np.concatenate(all_probs_pos, axis=0)\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "display(metrics_df)\n",
    "\n",
    "print(\"\\n===== Mean ± Std across folds =====\")\n",
    "for col in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "    print(f\"{col:10s}: {metrics_df[col].mean():.4f} ± {metrics_df[col].std():.4f}\")\n",
    "\n",
    "metrics_df.to_csv(\"cv_metrics_summary.csv\", index=False)\n",
    "print(\"\\nSaved to cv_metrics_summary.csv\")\n",
    "\n",
    "cm = confusion_matrix(all_true_labels, all_predictions)\n",
    "acc_micro = (cm.trace()) / cm.sum()\n",
    "print(f\"\\nMicro accuracy (all folds combined): {acc_micro:.4f}\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions, digits=4))\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "    yticklabels=[\"True 0\", \"True 1\"],\n",
    ")\n",
    "plt.title(\"Overall Confusion Matrix (all folds)\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(all_true_labels, all_probs_pos)\n",
    "ap = average_precision_score(all_true_labels, all_probs_pos)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(recall, precision, label=f\"All folds (AP = {ap:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Curve (5-fold combined)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Combined Average Precision: {ap:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDz-k6AFwiFl"
   },
   "source": [
    "# **Train Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "w9jC0kNpwkO1",
    "outputId": "c198a283-c793-4b2b-dde6-ec8e5d7b220d"
   },
   "outputs": [],
   "source": [
    "print(\"--- Training Final Model on All Data ---\")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "final_train_df = df_master\n",
    "final_train_dataset = Dataset.from_pandas(final_train_df).with_transform(transform)\n",
    "\n",
    "final_model = DeiTForImageClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "final_training_args = TrainingArguments(\n",
    "    output_dir=\"final_deit_model_training\",\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=15,\n",
    "    logging_steps=10,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.05,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    remove_unused_columns=False,\n",
    "    use_mps_device=torch.backends.mps.is_available(),\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "final_trainer = CustomTrainer(\n",
    "    model=final_model,\n",
    "    args=final_training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=final_train_dataset,\n",
    "    tokenizer=feature_extractor,\n",
    "    class_weights=class_weights_tensor,\n",
    ")\n",
    "\n",
    "final_trainer.train()\n",
    "\n",
    "final_export_dir = \"final_deit_model\"\n",
    "os.makedirs(final_export_dir, exist_ok=True)\n",
    "\n",
    "final_trainer.save_model(final_export_dir)\n",
    "feature_extractor.save_pretrained(final_export_dir)\n",
    "torch.save({\"id2label\": id2label, \"label2id\": label2id},\n",
    "           os.path.join(final_export_dir, \"label_map.pt\"))\n",
    "\n",
    "print(f\"--- Final Model Saved to: {final_export_dir} ---\")\n",
    "\n",
    "shutil.rmtree(\"final_deit_model_training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHpQjtYmx4Iu"
   },
   "source": [
    "# **Try final the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjRH_Fb1x6uN"
   },
   "outputs": [],
   "source": [
    "model = DeiTForImageClassification.from_pretrained(\"final_deit_model\")\n",
    "processor = DeiTImageProcessor.from_pretrained(\"final_deit_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTWa_0aWx9Zi",
    "outputId": "3489147e-4ada-4faf-8d44-4f285039ece5"
   },
   "outputs": [],
   "source": [
    "clf = pipeline(\n",
    "    \"image-classification\",\n",
    "    model= \"final_deit_model\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DD0MXE2mx_m7",
    "outputId": "fef7f1fd-0a85-45a8-c681-5d1d418fc972"
   },
   "outputs": [],
   "source": [
    "img_path = \"/content/Dataset/1/DM004_M_R.png\"\n",
    "\n",
    "print(clf(img_path, top_k=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMtGB3rJxtG_"
   },
   "source": [
    "# **Save all content to Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9Jvg6DRxsgU",
    "outputId": "aa91a488-6a23-4497-ede7-0abd354dddd8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, shutil, pathlib\n",
    "\n",
    "SAVE_DIR = \"/content/drive/MyDrive/colab_backups_deit\"\n",
    "SRC_ROOT = \"/content\"\n",
    "\n",
    "folder_prefixes = (\"export_deit_fold_\", \"training_deit_fold_\")\n",
    "extra_folders   = {\"Dataset\", \"sample_data\", \"final_deit_model\"}\n",
    "\n",
    "pathlib.Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name in os.listdir(SRC_ROOT):\n",
    "    src_path = os.path.join(SRC_ROOT, name)\n",
    "    if os.path.isdir(src_path):\n",
    "        if name.startswith(folder_prefixes) or name in extra_folders:\n",
    "            dst_path = os.path.join(SAVE_DIR, name)\n",
    "            print(f\"Copying folder {src_path} -> {dst_path}\")\n",
    "            shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
    "\n",
    "csv_src = os.path.join(SRC_ROOT, \"cv_metrics_summary.csv\")\n",
    "if os.path.exists(csv_src):\n",
    "    csv_dst = os.path.join(SAVE_DIR, \"cv_metrics_summary.csv\")\n",
    "    print(f\"Copying file {csv_src} -> {csv_dst}\")\n",
    "    shutil.copy2(csv_src, csv_dst)\n",
    "else:\n",
    "    print(\"cv_metrics_summary.csv not found in /content\")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPeSoOn4irOa"
   },
   "source": [
    "# **Grad-Cam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNgUWrgkAYu6",
    "outputId": "cf9b547d-0125-4506-96af-0edabf679800"
   },
   "outputs": [],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCeGFNpE30DQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from transformers import DeiTImageProcessor, DeiTForImageClassification\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER_PATH = \"final_deit_model\"\n",
    "IMAGE_PATH_1 = \"img/[1] DFU/DM115_F_R.png\"  \n",
    "IMAGE_PATH_2 = \"img/[1] DFU/DM115_F_L.png\" \n",
    "TARGET_CLASS_INDEX = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_transform(tensor, height=14, width=14):\n",
    "    result = tensor[:, 2:, :].reshape(\n",
    "        tensor.size(0),\n",
    "        height,\n",
    "        width,\n",
    "        tensor.size(2)\n",
    "    )\n",
    "    result = result.permute(0, 3, 1, 2)\n",
    "    return result\n",
    "\n",
    "class HuggingfaceToTensorModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(HuggingfaceToTensorModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DeiTImageProcessor.from_pretrained(MODEL_FOLDER_PATH)\n",
    "hf_model = DeiTForImageClassification.from_pretrained(MODEL_FOLDER_PATH)\n",
    "\n",
    "model = HuggingfaceToTensorModelWrapper(hf_model).to(device).eval()\n",
    "\n",
    "target_layers = [model.model.deit.encoder.layer[-1].layernorm_before]\n",
    "\n",
    "cam = GradCAM(\n",
    "    model=model,\n",
    "    target_layers=target_layers,\n",
    "    reshape_transform=reshape_transform\n",
    ")\n",
    "\n",
    "targets = [ClassifierOutputTarget(TARGET_CLASS_INDEX)]\n",
    "\n",
    "image_paths = [IMAGE_PATH_1, IMAGE_PATH_2]\n",
    "rgb_images = []          \n",
    "cam_visualizations = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in image_paths:\n",
    "    pil_img = Image.open(p).convert(\"RGB\")\n",
    "\n",
    "    img_np = np.array(pil_img).astype(np.float32) / 255.0 \n",
    "    rgb_images.append(img_np)\n",
    "\n",
    "    inputs = processor(images=pil_img, return_tensors=\"pt\")\n",
    "    input_tensor = inputs[\"pixel_values\"].to(device)  \n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :] \n",
    "\n",
    "    H, W, _ = img_np.shape\n",
    "    grayscale_cam_resized = cv2.resize(grayscale_cam, (W, H))\n",
    "\n",
    "    cam_vis = show_cam_on_image(img_np, grayscale_cam_resized, use_rgb=True)\n",
    "    cam_visualizations.append(cam_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(7, 4))\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"Grad-CAM Visualization (Target Class: {TARGET_CLASS_INDEX})\",\n",
    "    fontsize=16,\n",
    "    y=1.03\n",
    ")\n",
    "\n",
    "axes[0].imshow(rgb_images[0])\n",
    "axes[0].set_title(\"Original Right Foot\", fontsize=10, pad=4)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(rgb_images[1])\n",
    "axes[1].set_title(\"Original Left Foot\", fontsize=10, pad=4)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cam_visualizations[0])\n",
    "axes[2].set_title(\"Grad-CAM Right Foot\", fontsize=10, pad=4)\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(cam_visualizations[1])\n",
    "axes[3].set_title(\"Grad-CAM Left Foot\", fontsize=10, pad=4)\n",
    "axes[3].axis('off')\n",
    "\n",
    "fig.subplots_adjust(\n",
    "    wspace=0.05,\n",
    "    left=0.03,\n",
    "    right=0.97,\n",
    "    top=0.85,\n",
    "    bottom=0.05\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-NOc2Kxys-k1",
    "08IgchiktFty",
    "MRBw-L0EtWfp",
    "uOs1XD3tteF3",
    "tg_d61nLDhSn",
    "oDz-k6AFwiFl",
    "eHpQjtYmx4Iu"
   ],
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
